{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99af7aa1",
   "metadata": {},
   "source": [
    "# Tutorial for `musiF`\n",
    "\n",
    "`musiF` is a python library to analyse music scores. It is a tool to massively extract features from MusicXML and Musescore files. \n",
    "\n",
    "`musiF` was born in the context of the [Didone Project](https://didone.eu/) and, consequently,\n",
    "it is specialized in a 18th Century Italian Operas arias. However, it is likely helpful for the analysis intended to work in other repertoires as well.\n",
    "\n",
    "## Installation\n",
    "\n",
    "First, you should install Python > 3.10. We reccommend to use virtualenvs while you develop, so that you do not interfer with the other Python applications installed in your system.\n",
    "\n",
    "An easy way to do this is by using [`anaconda`](https://www.anaconda.com/products/distribution), especially if you are not used to commandline interface. Alternatively, you can use more standard methods such Python's `virtualenv` module, `pyenv`, `poetry`, `pdm`, and similar.\n",
    "\n",
    "In any case, to install, just use `pip install musif` from a command line inside your virtualenv.\n",
    "You can also use a jupyer notebook or console and the `!` special command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acec1e0f",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[31mERROR: /home/federico/musiF is not a valid editable requirement. It should either be a path to a local project or a VCS URL (beginning with bzr+http, bzr+https, bzr+ssh, bzr+sftp, bzr+ftp, bzr+lp, bzr+file, git+http, git+https, git+ssh, git+git, git+file, hg+file, hg+http, hg+https, hg+ssh, hg+static-http, svn+ssh, svn+http, svn+https, svn+svn, svn+file).\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -e /home/federico/musiF # TODO: change to pip install musif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91eac574",
   "metadata": {},
   "source": [
    "Now, let's import it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ea2c590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1.0\n"
     ]
    }
   ],
   "source": [
    "import musif\n",
    "print(musif.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cd214c",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "### If you are new to programming etc. read this\n",
    "\n",
    "If you are new to Python, we suggest you to read a tutorial for it.\n",
    "In the following, we will use some technical terminology. In general keep in mind the following:\n",
    "\n",
    "* a _function_ is a way to represent code that is convenient for humans. You can think about functions as the mathematical functions, with some input and some output. However, some programming languages call them _procedures_; this is not the case of Python, but this name allow grasp what functions are, after all: they are successions of commands that the computer has to execute.\n",
    "\n",
    "* an _object_ is a computational way to represent information in the memory of computers; you can think about objects as real concepts of the real world: object have properties (in Python named _fields_) and functionalities (named _methods_). For instance, an object could be a vehicle, which has some properties (length, maximum speed, number of wheels) and some functionalities (accelerate, decelerate, stop). Objects can also have specializations (named _children_): in our example, a child of vehicle could be the car and another child could be the bike: they have different properties and apply the functionalities in a different way. Both the vehicle, the car, and the bike may have instances: the car that you use everyady to go at work is different from the one of your friend even if they have the same exact properties, because they are two different concrete objects. Technically, those two cars are two _instances_ of the same _class_. To create an instance you have to call a function, which takes some argument such as the class, and other properties, and that will return the instance. To use `musiF`, you don't need to know a lot about objects, but while you search the web it is good to have a little of knowledge.\n",
    "\n",
    "* a _dataframe_ is another way to represent information for computers. They are designed to be extremely efficient, even if sometimes some aspect of the information can get lost, and for this reason are used for data science problems. You can think about a _dataframe_ as to a table, with rows and columns. Usually, rows are _instances_ while columns are _properties_. In data science, these words often become _samples_ and _features_/_variables_. A typical operation is to select only certain columns (properties) or only certain rows (instances) to select subset of the data or to modify the data itself.\n",
    "* don't be scared of using web search engines such as Google: searching the web in a proper way is one of the most important skills a programmer has!\n",
    "\n",
    "### Main objects\n",
    "\n",
    "When using `musif`, you will usually interface with two objects:\n",
    "1. [`FeaturesExtractor()`](API/musif.extract.html#musif.extract.extract.FeaturesExtractor), which read scores in MusicXML and MuseScore format and computes a Dataframe containing all the extracted features. In the simplest case, each row represents a music score, while each column represents a feature.\n",
    "2. [`DataProcessor()`](API/musif.process.html#musif.process.processor.DataProcessor), which takes the dataframe with all the features in it and post-processes it to clean, improve, and possibly modify some of the features.\n",
    "\n",
    "These two objects take as input two different configurations that modify their behaviour. In other words, the function that create the instances of `FeaturesExtractor` and `DataProcessor` can accept a wide range of arguments.\n",
    "\n",
    "But let's proceed step-by-step!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c2b552",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "For starting, downaload one or more of the following datasets:\n",
    "\n",
    "...\n",
    "\n",
    "You should put the MusicXML data under the `data` directory aside to this notebook!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab6f329",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Let's create a configuration for our experiment. Configuration can be expressed using a yaml file or with key-value arguments. Key-value arguments are something similar to a dictionary: on one side there is a _key_ which must be unique in the dictionary; each _key_ is associated to a _value_, that can also be repeated. Python can retrieve a a value using its key in  avery efficient way!\n",
    "\n",
    "First, we'll need to import the class that describes how a `Configuration` is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27ac4ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from musif.config import ExtractConfiguration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c511bb",
   "metadata": {},
   "source": [
    "Now, we can call its constructor to obtain a configuration object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fe4511f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "config = ExtractConfiguration(\n",
    "    None,\n",
    "    musescore_dir=\"data\",\n",
    "    limit_files=glob.glob(\"**/*.mid\", recursive=True, root_dir='data'),\n",
    "    basic_modules=[\"scoring\"],\n",
    "    features=[\"core\", \"ambitus\", \"interval\", \"tempo\", \n",
    "              \"density\", \"texture\", \"lyrics\", \"scale\", \n",
    "              \"key\", \"dynamics\", \"rhytm\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051ca8fe",
   "metadata": {},
   "source": [
    "As you can see, the configuration has 3 values in this case:\n",
    "1. `None`: this is just a place-holder: it would usually be the `yaml` file containing the configuration; since we do not need it, we use `None`\n",
    "2. the directory where MuseScore will look for the data; we'll use MuseScore to convert MIDI files to MusicXML, so you should first [download](https://musescore.org/en/download) and install it (Note: if you are running this notebook on a remote server without GUI, make sure to have a virtual display set up in the shell running this notebook, e.g. `Xvfb :99 & export DISPLAY=:99`)\n",
    "3. `basic_modules` are modules used to compute basic features needed for the successive ones\n",
    "4. `features` are the features that will be computed\n",
    "\n",
    "Each feature name is a word that refers to a set of features and to a musiF package.\n",
    "You can also create your own [custom features](./Custom_features.html), but it's a more advanced topic.\n",
    "For now, just think about `basic_modules` and `features` as the same thing, but with a precedence order. We will see the true difference later on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a59048",
   "metadata": {},
   "source": [
    "\n",
    "Now that we have our configuration, we pass it to the function that creates `FeaturesExtraction` objects. This function is exactly named `FeaturesExtraction`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b900810d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from musif.extract.extract import FeaturesExtractor\n",
    "\n",
    "extractor = FeaturesExtractor(config)\n",
    "\n",
    "# Note: we could also pass the configuration values directly to FeaturesExtractor, like this:\n",
    "# \n",
    "# extractor = FeaturesExctractor(\n",
    "#     None,\n",
    "#     musescore_dir=\"/home/federico/arias_example/\",\n",
    "#     basic_modules=[\"scoring\"],\n",
    "#     features=[\"core\", \"ambitus\", \"interval\", \"tempo\", \n",
    "#               \"density\", \"texture\", \"lyrics\", \"scale\", \n",
    "#               \"key\", \"dynamics\", \"rhytm\"]\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343373ac",
   "metadata": {},
   "source": [
    "Before of starting the extraction, we also need to tell MuseScore the type of files it should look for. In this case, we want it looks for files with extension `'.mid'`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02361615",
   "metadata": {},
   "outputs": [],
   "source": [
    "import musif.musescore.constants as musescore_c\n",
    "musescore_c.MUSESCORE_FILE_EXTENSION = '.mid'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756f12ba",
   "metadata": {},
   "source": [
    "Now, we can start the extraction using the method `extract`. It will return a `dataframe`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53a6c61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;37m                                               --- Analyzing scores ---\n",
      "                                                \u001b[0m\n",
      "\u001b[1;37m                                               --- Analyzing scores ---\n",
      "                                                \u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███████████████████████████▋                                                      | 59/175 [01:44<03:02,  1.57s/it]"
     ]
    }
   ],
   "source": [
    "df = extractor.extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e92d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To show the dataframe in a Jupyter notebook, just use it as last instruction of the cell, like this:\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b29fedc",
   "metadata": {},
   "source": [
    "## Post-processing\n",
    "\n",
    "Most of the features we have computed actually need some post-processing, for instance to replace `NaN` with 0, merge columns, remove features created while computing other features.\n",
    "\n",
    "For this, we need another configuration. However, we'll use the default configuration, so we'll pass `None` in place of the yaml file/configuration object. You can do the same thing with the `FeaturesExtractor` as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c706fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from musif.process.processor import DataProcessor\n",
    "\n",
    "processed_df = DataProcessor(df, None).process().data\n",
    "processed_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1d6bd3",
   "metadata": {},
   "source": [
    "As you see, the columns are now half than before!\n",
    "\n",
    "Let's try to remove `NaN`..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df5c5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df.dropna(axis=1, inplace=True)\n",
    "processed_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc69508",
   "metadata": {},
   "source": [
    "The dataset was not very well formatted and this is the reason why only a few features remain.\n",
    "\n",
    "But let's try to classify them. We will setup a feature-learning approach where the model learns to classify each sample in the dataset. The usual way to do this would be using an autoencoder architecture, but since `sklearn` \n",
    "\n",
    "For this, we will use `sklearn` and its Multilayer Perceptron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373d30ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# removing FileName and Id\n",
    "if 'FileName' in processed_df:\n",
    "    del processed_df['FileName']\n",
    "if 'Id' in processed_df:\n",
    "    del processed_df['Id']\n",
    "\n",
    "processed_df.select_dtypes([float, int])\n",
    "\n",
    "model = make_pipeline(\n",
    "    OrdinalEncoder(), # give a cardinal number to features that are categories\n",
    "    StandardScaler(), # subtract the mean and scale between -1 and +1\n",
    "    MLPRegressor(\n",
    "        hidden_layer_sizes=(128, 32, 8, 2, 8, 32, 128, ), # the output size is the same as the number of labels\n",
    "        activation=\"relu\",\n",
    "        solver=\"adam\",\n",
    "        alpha=0,                 # regularizer L2 weight in ADAM\n",
    "        batch_size=5,\n",
    "        learning_rate_init=5e-5, \n",
    "        max_iter=10**3,\n",
    "        tol=1e-32,\n",
    "        early_stopping=False,\n",
    "        beta_1=1e-9,             # Adam decay rate for momentum 1\n",
    "        beta_2=0.999,            # Adam decay rate for momentum 2\n",
    "        epsilon=1e-8,            # Adam numerical stability\n",
    "        random_state=934,\n",
    "        # shuffle=True  \n",
    "    )\n",
    ")\n",
    "\n",
    "# the next call will take some time...\n",
    "model.fit(processed_df, processed_df.index)\n",
    "y_hat = model.predict(processed_df)\n",
    "print(f\"Macro-averaged F1 score: {f1_score(processed_df.index, y_hat, average='macro')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ade2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75abded",
   "metadata": {},
   "source": [
    "Now, we will attach a method `transform` to the MLPClassifier which returns the activations at the inner layer with 2 outputs, that we interpret as latent features.\n",
    "\n",
    "Then, we plot the music scores according to the learned feature space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278cdf51",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlpclassifier = model['mlpclassifier']\n",
    "\n",
    "def mytransform_method(X):\n",
    "    activations = [None for _ in range(mlpclassifier.n_layers_)]\n",
    "    activations[0] = X\n",
    "    X = mlpclassifier._forward_pass(activations)[-6]\n",
    "    return X\n",
    "    # return PCA(2).fit_transform(X)\n",
    "\n",
    "mlpclassifier.transform = mytransform_method\n",
    "\n",
    "learned_features = model.transform(processed_df)\n",
    "\n",
    "learned_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4102a187",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn\n",
    "seaborn.scatterplot(x=learned_features[:, 0], y=learned_features[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2afc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "learned_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7cf96b",
   "metadata": {},
   "source": [
    "For comparison, let's plot the feature space learned by PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e64c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca_pipeline = make_pipeline(\n",
    "    OrdinalEncoder(), StandardScaler(), PCA(2)\n",
    ")\n",
    "data_pca = pca_pipeline.fit_transform(processed_df)\n",
    "seaborn.scatterplot(x=data_pca[:, 0], y=data_pca[:, 1])"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
